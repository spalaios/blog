Probabilistic Counting with HyperLogLog: Under the Hood

Part 1
Let's start with problem statements : 
- You are a software engineer who has been tasked to build a feature/api where you show the count of either of these requests
    - total unique users who have visited your website.
    - total unique search queries done on your platform
    - total unique IP addresses visiting a server

A generalised version of the above problems statements will be :
Give the cardinality of all the items

Example :

[
  { "id": 1, "name": "Alice" },
  { "id": 2, "name": "Bob" },
  { "id": 1, "name": "Alice" }
]
if we measure the cardinality by "id", then cardinality = 2

//show the image of 5 cubes 
cubes cardinality = 5

Now that we understand the requirement, the obvious solution that comes to mind is using a HashMap to track the unique items. Let's walk through the process with our 5 cubes:

* We start with an empty HashMap.
* We iterate through each cube.
* For each cube, we check if it's already a key in our HashMap.
* If the cube is already in the map, we've seen it before, so we do nothing.
* If the cube is *not* in the map, we add it as a new key.
* Once we've processed all cubes, the number of entries in the HashMap gives us the total count of unique cubes.
Let's increase the size of the cubes to say 1 billion. 

//show the image of billion cubes
if we were to follow the hashmap building process here's how our hashmap would have looked 
{
  "cube_bright_green": 1,
  "cube_red": 1,
  "cube_blue": 1,
  "cube_gold": 1,
  "cube_blue_violet": 1,
  ...
  // and so on, up to billion of unique entries
}

You see the problem above a billion unique entries would have been created.

Let's calculate the approximate total space that will be consumed if the hashmap has 1 billion entries 
This could easily consume a lot memory potentially crashing the system.

Key : "cube_bright_green" (string)
    . Avg string length ~20 characters
    . UTF-16 encoding : 2 bytes/character -> 20 * 2 = 40 bytes
    . Object overhead + hash + pointers : ~24 bytes
    . Total key size ~ 64 bytest

Value : int
    . Just an integer -> 4 bytes
    . Padding + reference overhead → ~12–16 bytes in object form 

HashMap overhead per entry
    . Entry object overhead (hash, key ref, value ref, next pointer): ~32 bytes

Key:        ~64 bytes
Value:      ~16 bytes
Entry node: ~32 bytes
-------------------------
Total:      ~112 bytes per entry

Final Calculation for 1 billion+ will be
1,000,000,000 × 112 bytes = 112,000,000,000 bytes = 112 GB

Assuming the hashmap with load factor of 0.75 means the hashmap will resize when it's 75% full, so to support 1 billion entries, the capacity needs to be larger than 1 billion (1/0.75 = 1.33), so that will shoot up the memory space to ~150GB.

NOTE : The estimates above is done for HashMap used in Java and can vary based on the JVM runtime, architecture and specific object implemetation.

What problems would we face if we went ahead with this solution:
. You would need a high memory machine (>= 256 GB RAM). Making it an expensive choice
. Lookup performace would degrade
    - While the avg lookup is O(1), collisions can make worst-case O(n) in a poorly implemented hashmap or O(log n) in tree based used in some languages (Java 8+)
    - Even avg case can slow down due to cache misses with a massive memory footprint.
. Garbage collection and rehashing could cause major performace hits
    - The 1 billion keys of the hashmap are live and has to maintained in the heap memory directly putting a lot of pressure on the garbage collector. With this scale, stop the world GC pauses can last seconds to minutes
    - Rehashing a map with million or billions of entries is a very expensive operation that can pause your application

But if a simple HashMap consumes hundreds of gigabytes, how can anything track billions of unique items in just kilobytes? The answer lies in a clever probabilistic approach. In Part 2, we'll lift the hood on HyperLogLog and see exactly how it achieves this seemingly impossible feat.


Part 2

To understand HyperLogLog, let's start with basic coin flip probabilities.

image - 1 coin showing head
The probability of getting head from a single coin is 1/2

image - 5 coins showing head
The probability of getting all coins with head is 1/2^5

image - 20 coins showing head
The probability of getting all coins with head is 1/2^20

We can generalize this pattern. The probability of getting k consecutive heads is 1/2^k.

Here's the core insight: if you observe 5 consecutive heads, you've likely made around 32 (2^5) total flips. Similarly, seeing 20 consecutive heads suggests approximately 1,048,576 total flips.
HyperLogLog builds on this principle. When we see k consecutive heads, we estimate that 2^k total flips occurred. This 2^k value represents our estimate of unique elements encountered.

<image of 5 cubes here>
Now let's apply this coin flip concept to our cube colors. We'll pass each color through a hash function that generates a 32 or 64-bit binary string.

Why use binary strings? Think of each bit as a coin flip result. A '0' represents heads, and '1' represents tails. The entire binary string simulates a sequence of coin flips, where each bit has an equal probability of being 0 or 1.

//Now you might ask why binary string ?
//we're treating the binary output as a sequence of coin flips, where each bit position has equal probability of being 0 or 1

Let's see this in action with our cube colors
Here I have passed all the cube colors into the hash function and generated its corresponding binary string 

red  :  0010011010001101110000011100100011001110111010000101011101001010
blue : 0000110000111011011000000000111000110001001100111100011110001001
green :0000101110011110000001110101111111100001010101100001101000111110
yellow :  0000111110100100100010000101101010111001000010011110011100000101
purple :  0001000100101001000110000010010010100000010110001011111101010101

Note : I have used xxHash to generate the binary string here since it is fast, non-cryptographic and has good distribution. Output may vary depending on the seed value used by the hash function.

//We will store the longest run of leading 0s among all the binary string we have seen. 
//In this case it can be anyone among (blue, green, yellow) having 4 0s. 

Next, we examine the leading zeros in each binary string. We store the longest run of leading 0s among all strings we've processed. In our example, blue, green, and yellow each have 4 leading zeros.

//Why are we taking the string with largest leading 0s?
//The largest value will tell us how many unique colors have we seen till now in our case it is 2^4 = 16.

Why focus on the maximum leading zeros? This value estimates our total unique elements. With 4 leading zeros, we estimate 2^4 = 16 unique colors.

However, there's a clear problem with this approach. Our estimate of 16 is far from the actual count of 5 colors. This gets worse with extreme cases.

Consider this scenario: suppose one color generated this binary string:
blue : 0000000000000000000000000000000000000000000000000000000000000001

as per our logic the largest leading 0s will be 63 which means we might have seen 2^63 colors till now which obviously orders of magnitude far from what we have.
This illustrates the fundamental flaw in our single-value approach. One outlier can completely skew our estimate.

To solve this skew problem, we introduce buckets. Each bucket receives hash values and stores the maximum leading zeros found within that bucket.

But why do buckets help? They leverage several statistical principles:
a. The law of large numbers kicks in with multiple samples
b. Averaging many estimates produces stable results
c. Extreme outliers get diluted across the population

Think of this like a product rating system. A single 5-star review isn't very meaningful. 
However, averaging 1,000+ ratings gives you a trustworthy result. 
Similarly, more buckets reduce our error rate, though they require additional memory.

Let's use 1024 buckets for our example, indexed from 0 to 1023.
How do we assign our binary string to our buckets?
1. Take the first n (10 in our case hence 1024 buckets) bits of each binary string
2. Convert these bits to a decimal value (this becomes the bucket index)
3. Count the leading zeros in the remaining bits
4. Store this count in the corresponding bucket

Let's walk through this process with our cube colors:

red  :  0010011010 - 001101110000011100100011001110111010000101011101001010
the first 10 bits : 0010011010 -> 154
remaining bits : 001101110000011100100011001110111010000101011101001010 -> leading 0s is 2 (0s from start of the string)
So we will store 3 in bucket index 154

blue : 0000110000 - 111011011000000000111000110001001100111100011110001001
the first 10 bits - 0000110000 -> 48
remaining bits - 111011011000000000111000110001001100111100011110001001 -> leading 0s is 0
So we will store 1 in bucket index 48

green : 0000101110 - 011110000001110101111111100001010101100001101000111110
the first 10 bits - 0000101110 -> 46
remaining bits - 011110000001110101111111100001010101100001101000111110 -> leading 0s is 1
So we will store 2 in bucket index 46

yellow :  0000111110 - 100100100010000101101010111001000010011110011100000101
the first 10 bits - 0000111110 -> 62
remaining bits - 100100100010000101101010111001000010011110011100000101 -> leading 0s is 0
So we will store 1 in bucket index 62

purple :  0001000100 - 101001000110000010010010100000010110001011111101010101
the first 10 bits - 0001000100 -> 68
remaining bits - 101001000110000010010010100000010110001011111101010101 -> leading 0s is 0
So we will store 1 in bucket index 68

NOTE: 
a. if in case the same bucket no. appears and if the leading zero count is greater that what is present in that bucket index we update it.
b. we are adding +1 to every value (reason explained later)

| Color  | Bucket Index           | Remaining Bits (truncated) | Leading Zeros (LZ) | Stored Value (`ρ = LZ + 1`) |
| ------ | ---------------------- | -------------------------- | ------------------ | --------------------------- |
| red    | `0010011010` = **154** | `00110111...`              | **2**              | **3**                       |
| blue   | `0000110000` = **48**  | `11101101...`              | **0**              | **1**                       |
| green  | `0000101110` = **46**  | `01111000...`              | **1**              | **2**                       |
| yellow | `0000111110` = **62**  | `10010010...`              | **0**              | **1**                       |
| purple | `0001000100` = **68**  | `10100100...`              | **0**              | **1**                       |

NOTE: LZ stands for leading zeros

Why stored value is LZ + 1 ?
HyperLogLog works with the formula -> Z = ∑(2^-M[i]) for i = 1 to m

Where :
m = number of buckets (e.g., 1024)
M[i] = the stored value in bucket i (which is LZ + 1)
Z = a value used in the cardinality estimate

So if you store just LZ(leading zero) and some bucket ends up storing LZ=0, it means,
- the element had 1 as the first bit
- So we'd store 0
- Then as per the formula given above 2^-0 = 1 which overpowers the average because values like 2^-6 = 0.015625 or 2^-10 = 0.000976 comparing the result 1 seems very large and mess up the estimate
  so if we store LZ+1 then for 0 we store 1 as the count. so 2^-1 = 0.5 which is still greater than other values but not overpowering as 1


Rule of Thumb:
You choose n (number of bits for bucket index) based on the desired error rate.

Error Rate vs Buckets Table
n	Buckets (m = 2^n)	Relative Error (%)	Memory (bytes)
4	16	                ~26%	            16
5	32	                ~18%	            32
6	64	                ~13%	            64
10	1024	            ~3.2%	            1024
12	4096	            ~1.6%	            4096
14	16,384	            ~0.81%	            16,384

Now we can apply the HyperLogLog formula

E = α_m * m^2 / Z

Where:
Z = defined above
m = number of buckets (i.e. 2^n)
M[i] = value stored in bucket i (which is LZ + 1)
α_m = bias correction constant, depends on m
Z = sum of 2^-M[i] across all buckets

What is α_m?
a. Without this constant our estimates will be too low or too high depending upon the no. of buckets (m)
b. the value of this constant depends on the no. of buckets

If m = 16:      αₘ = 0.673
If m = 32:      αₘ = 0.697
If m = 64:      αₘ = 0.709
If m ≥ 128:     αₘ = 0.7213 / (1 + 1.079 / m)

so in our case since our bucket count m = 1024 our constant value is 0.720544

Using this formula our total color counts for HLL comes around 740 which is very high. This happens because most buckets remain empty, contributing 2^0 = 1 to our calculation. These empty buckets artificially inflate the average
For small cardinalities, HyperLogLog switches to a more accurate method: linear counting.

So if the E (estimate) <= (5 / 2) * m

Formula for linear counting

E = m * ln(m / V)

E = estimated number of unique elements
m = total number of buckets (e.g., 1024)
V = number of buckets that still have the value 0
ln = natural logarithm (log base e)

Using the formula we get :

E = 1024 * ln(1024 / 1019)
  ≈ 1024 * ln(1.0049)
  ≈ 1024 * 0.00489
  ≈ 5

So the estimate is 5 unique elements, which is accurate if you've only seen 5.

Now let's calculate the storage requirements for our HyperLogLog system.
With a 64-bit hash function:
a. Maximum leading zeros: 64
b. Maximum LZ + 1 value: 65
c. Bits needed to store 0-65: 7 bits per bucket

This gives us our final storage calculation:
a. m = 1024 buckets
b. 7 bits per bucket

1024 buckets * 7 bits = 7168 bits = 7168 / 8 = 896 bytes = 0.875 KB

The total space required will be 0.875 KB.

Sparse Encoding (Optional Optimization)
For small cardinalities, you can use a sparse representation:
Instead of allocating memory for all buckets,
Store only non-zero entries using (bucket index, value) pairs.
This can shrink usage to hundreds of bytes for small datasets.
Redis and Google BigQuery use this trick: start sparse, switch to dense when needed.

Final Thoughts on Why HyperLogLog is awesome
a. Tracks billions of unique values in just kilobytes
b. gives an estimate (not exact), but that's often good enough
c. Used in Redis, Google BigQuery, Postgres etc



